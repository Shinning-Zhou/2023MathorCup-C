{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data0.csv')\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"]) \n",
    "date_begin=pd.to_datetime('2021-01-01')\n",
    "date_end=pd.to_datetime('2022-12-31')\n",
    "data=data[(data['date']>=date_begin)&(data['date']<=date_end)]\n",
    "\n",
    "prediction=pd.read_csv('problem1_prediction.csv')\n",
    "prediction['ds'] = pd.to_datetime(prediction['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str='2023-01-02'\n",
    "date_step=29\n",
    "new_edge_value=1000\n",
    "load_value=10000\n",
    "res_value=100000\n",
    "step=100\n",
    "\n",
    "def cost_func(u,v,not_used,current_flow,max_flow):\n",
    "    load_rate=current_flow/max_flow\n",
    "    res_flow=max_flow-current_flow\n",
    "    if u=='s' or v=='t':\n",
    "        return 0\n",
    "    if '-pre' in u or '-next' in v:\n",
    "        return 0\n",
    "    return np.ceil(not_used*new_edge_value +load_rate*load_value+res_value/(res_flow+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all_list=[]\n",
    "date=pd.to_datetime(date_str)\n",
    "for cnt in range(date_step):\n",
    "    \n",
    "    unique_routes = data[['place1', 'place2']].drop_duplicates()\n",
    "    edge_info=pd.DataFrame(columns=['max_flow','place1','place2','current_flow'])\n",
    "    for index, row in unique_routes.iterrows():\n",
    "        place1,place2=row['place1'],row['place2']\n",
    "        if 'DC5' in [place1,place2]:\n",
    "            continue\n",
    "        max_flow_1=data[(data['place1']==place1) & (data['place2']==place2)]['num'].max()\n",
    "        max_flow_2=prediction[(prediction['place1']==place1) & (prediction['place2']==place2)]['yhat'].max()\n",
    "        max_flow=max(max_flow_1,max_flow_2)\n",
    "        current_flow=prediction[(prediction['ds']==date) & (prediction['place1']==place1) & (prediction['place2']==place2)]['yhat'].values[0]\n",
    "        edge_info.loc[index]=[max_flow,place1,place2,current_flow]\n",
    "    edge_info=edge_info.reset_index()\n",
    "    edge_info.head() \n",
    "    \n",
    "    unique_points=pd.concat([data['place1'],data['place2']],ignore_index=True).drop_duplicates()\n",
    "    point_info=pd.DataFrame(columns=['place','res','max_flow','in_flow','out_flow'])\n",
    "    for index, value in unique_points.iteritems():\n",
    "        if value=='DC5':\n",
    "            continue\n",
    "        in_flow=prediction[(prediction['ds']==date)&(prediction['place2']==value)&(prediction['place1']!='DC5') ]['yhat'].sum( )\n",
    "        out_flow=prediction[(prediction['ds']==date)&(prediction['place1']==value)&(prediction['place2']!='DC5')]['yhat'].sum( )\n",
    "        res=out_flow-in_flow\n",
    "        \n",
    "        max_in_sum_1_temp=data[(data['place2']==value)].groupby('date').sum()\n",
    "        max_in_sum_1=max_in_sum_1_temp['num'].max()\n",
    "        max_in_sum_2_temp=prediction[(prediction['place2']==value)][['yhat','ds']].groupby('ds').sum()\n",
    "        max_in_sum_2=max_in_sum_2_temp['yhat'].max()\n",
    "        if np.isnan(max_in_sum_1):\n",
    "            max_in_sum_1=0\n",
    "        if np.isnan(max_in_sum_2):\n",
    "            max_in_sum_2=0\n",
    "        max_in_sum=max(max_in_sum_1,max_in_sum_2)\n",
    "        \n",
    "        max_out_sum_1_temp=data[(data['place1']==value)].groupby('date').sum()\n",
    "        max_out_sum_1=max_out_sum_1_temp['num'].max()\n",
    "        max_out_sum_2_temp=prediction[(prediction['place1']==value)].groupby('ds').sum()\n",
    "        max_out_sum_2=max_out_sum_2_temp['yhat'].max()\n",
    "        if np.isnan(max_out_sum_1):\n",
    "            max_out_sum_1=0\n",
    "        if np.isnan(max_out_sum_2):\n",
    "            max_out_sum_2=0\n",
    "        max_out_sum=max(max_out_sum_1,max_out_sum_2)\n",
    "        \n",
    "        point_info.loc[index]=[value,res,max(max_in_sum,max_out_sum),in_flow,out_flow]\n",
    "    point_info=point_info.reset_index()\n",
    "    point_info.head()\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    # 添加节点\n",
    "    G.add_node('s')  # 源节点\n",
    "    G.add_node('t')  # 汇节点 \n",
    "\n",
    "\n",
    "    for index, row in point_info.iterrows():\n",
    "        point,max_flow,res,in_flow,out_flow=row['place'],row['max_flow'],row['res'],row['in_flow'],row['out_flow']\n",
    "        G.add_node(point)\n",
    "        G.add_node(point+'-pre')\n",
    "        G.add_node(point+'-next')\n",
    "        \n",
    "        G.add_edge(point+'-pre', point, capacity=max(max_flow-in_flow,0), weight=0,flow=0,origin_capacity=max(0,max_flow-in_flow))\n",
    "        G.add_edge(point, point+'-next', capacity=max(max_flow-out_flow,0), weight=0,flow=0,origin_capacity=max(0,max_flow-in_flow))\n",
    "    # print(G.nodes())\n",
    "    # 添加边\n",
    "    for index, row in edge_info.iterrows():\n",
    "        u,v,max_flow,current_flow=row['place1'],row['place2'],row['max_flow'],row['current_flow']\n",
    "        cost=cost_func(u,v,True,current_flow,max_flow)\n",
    "        G.add_edge(u+'-next', v+'-pre', capacity=max(0,max_flow-current_flow), weight=cost,flow=current_flow,origin_capacity=max_flow)\n",
    "\n",
    "    for index, row in point_info.iterrows():\n",
    "        place,res,max_flow=row['place'],row['res'],row['max_flow']\n",
    "        if res>0:\n",
    "            G.add_edge('s', place+'-pre', capacity=1e8, weight=0,flow=0,origin_capacity=1e8)\n",
    "        else:\n",
    "            G.add_edge(place+'-next', 't', capacity=1e8, weight=0,flow=0,origin_capacity=1e8)\n",
    "\n",
    "\n",
    "    flow_to_DC5=prediction[(prediction['ds']==date) & (prediction['place2']=='DC5')]['yhat'].sum()\n",
    "    flowDict=nx.max_flow_min_cost(G, 's', 't', capacity='capacity', weight='weight')\n",
    "    max_flow=sum(flowDict[node1][node2] for node1 in flowDict for node2 in flowDict[node1])\n",
    "    print(flow_to_DC5,max_flow)\n",
    "    min_cost_list=[]\n",
    "    flow_dict_list=[]\n",
    "\n",
    "    add_num,i=1,0\n",
    "    while i<flow_to_DC5:\n",
    "        # print(f'{i}/{flow_to_DC5}')\n",
    "        G.nodes['s']['demand']=-add_num\n",
    "        G.nodes['t']['demand']=add_num\n",
    "        i+=add_num\n",
    "        if add_num<step:\n",
    "            add_num+=1\n",
    "        flowDict = nx.min_cost_flow(G, demand=\"demand\", capacity='capacity', weight='weight')\n",
    "        min_cost=nx.cost_of_flow(G,flowDict)\n",
    "        min_cost_list.append(min_cost)\n",
    "        flow_dict_list.append(flowDict)\n",
    "        # print(min_cost)\n",
    "        for u, v in G.edges():\n",
    "            if flowDict[u][v]!=0:\n",
    "                # print(u,v,flowDict[u][v])\n",
    "                G[u][v]['capacity']-=flowDict[u][v]\n",
    "                G[u][v]['flow']  += flowDict[u][v]\n",
    "                G[u][v]['weight']=cost_func(u,v,False,G[u][v]['flow'],G[u][v]['origin_capacity'])\n",
    "                # print(u,v,G[u][v]['weight'])\n",
    "    result_all_list.append(flow_dict_list)\n",
    "    date=date+pd.DateOffset(days=1)\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "date=pd.to_datetime(date_str)\n",
    "for index,flow_dict_list in enumerate(result_all_list):\n",
    "    result_dict={}\n",
    "    for d in flow_dict_list:\n",
    "        for k1, v1 in d.items():\n",
    "            if k1 not in result_dict:\n",
    "                result_dict[k1] = {}\n",
    "            for k2, v2 in v1.items():\n",
    "                result_dict[k1][k2] = result_dict[k1].get(k2, 0) + v2\n",
    "    result_dict_new={}          \n",
    "    for k1,v1 in result_dict.items():\n",
    "        for k2,v2 in v1.items():\n",
    "            if v2!=0:\n",
    "                k1=k1.replace('-pre','').replace('-next','')\n",
    "                k2=k2.replace('-pre','').replace('-next','')\n",
    "                if k1==k2:\n",
    "                    continue\n",
    "                if k1 not in result_dict_new:\n",
    "                    result_dict_new[k1] = {}\n",
    "                result_dict_new[k1][k2] = v2\n",
    "    result_dict=result_dict_new\n",
    "    for k1,v1 in result_dict.items():\n",
    "        for k2,v2 in v1.items():\n",
    "            if not(k1=='s' or k2=='t'):\n",
    "                max_flow=edge_info[(edge_info['place1']==k1) & (edge_info['place2']==k2)]['max_flow'].values[0]\n",
    "                origin_flow=edge_info[(edge_info['place1']==k1) & (edge_info['place2']==k2)]['current_flow'].values[0]\n",
    "                result_dict[k1][k2] = [v2,(v2+origin_flow)/max_flow,max_flow,origin_flow]\n",
    "            else:\n",
    "                result_dict[k1][k2] = [v2,0,0,0]\n",
    "    df_list.append(pd.DataFrame([(k1, k2, v2[0],v2[1],v2[2],v2[3],date) for k1,v1 in result_dict.items() for k2,v2 in v1.items()], columns=['place1', 'place2', 'flow','load_rate','max_flow','origin_flow','date']))\n",
    "    date=date+pd.DateOffset(days=1)\n",
    "    \n",
    "df = pd.concat(df_list)\n",
    "df.to_csv('problem2_02_30.csv', index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mothercup2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
