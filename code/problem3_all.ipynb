{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place1</th>\n",
       "      <th>place2</th>\n",
       "      <th>date</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC3</td>\n",
       "      <td>DC5</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC3</td>\n",
       "      <td>DC10</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DC3</td>\n",
       "      <td>DC14</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DC5</td>\n",
       "      <td>DC3</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC5</td>\n",
       "      <td>DC9</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place1 place2       date  num\n",
       "0    DC3    DC5 2021-01-01    3\n",
       "1    DC3   DC10 2021-01-01    4\n",
       "2    DC3   DC14 2021-01-01    4\n",
       "3    DC5    DC3 2021-01-01   41\n",
       "4    DC5    DC9 2021-01-01    3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data0.csv')\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"]) \n",
    "date_begin=pd.to_datetime('2021-01-01')\n",
    "date_end=pd.to_datetime('2022-12-31')\n",
    "data=data[(data['date']>=date_begin)&(data['date']<=date_end)]\n",
    "\n",
    "prediction=pd.read_csv('problem1_prediction.csv')\n",
    "prediction['ds'] = pd.to_datetime(prediction['ds'])\n",
    "\n",
    "\n",
    "date_str='2023-01-01'\n",
    "date_step=31\n",
    "new_edge_value=1000\n",
    "load_value=10000\n",
    "create_value=1000\n",
    "res_value=100000\n",
    "step=1\n",
    "max_edge_flow=505833\n",
    "\n",
    "data.head()\n",
    "# print(date+ pd.Timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(u,v,not_used,current_flow,max_flow,not_created):\n",
    "    load_rate=current_flow/max_flow\n",
    "    res_flow=max_flow-current_flow\n",
    "    if u=='s' or v=='t':\n",
    "        return 0\n",
    "    if '-pre' in u or '-next' in v:\n",
    "        return 0\n",
    "    return np.ceil(not_used*new_edge_value +load_rate*load_value+res_value/(res_flow+1)+not_created*create_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 27861127\n",
      "0\n",
      "67 29552845\n",
      "1\n",
      "83 28252798\n",
      "2\n",
      "79 26760552\n",
      "3\n",
      "80 24809169\n",
      "4\n",
      "81 23556155\n",
      "5\n",
      "83 22694371\n",
      "6\n",
      "79 22167600\n",
      "7\n",
      "80 20989983\n",
      "8\n",
      "96 20393569\n",
      "9\n",
      "87 19728779\n",
      "10\n",
      "87 18703727\n",
      "11\n",
      "90 17895129\n",
      "12\n",
      "80 18152778\n",
      "13\n",
      "83 18335618\n",
      "14\n",
      "82 17281341\n",
      "15\n",
      "98 17172400\n",
      "16\n",
      "91 16829064\n",
      "17\n",
      "88 16362563\n",
      "18\n",
      "97 16591120\n",
      "19\n",
      "89 15757350\n",
      "20\n",
      "88 16051084\n",
      "21\n",
      "95 15860635\n",
      "22\n",
      "111 16043251\n",
      "23\n",
      "103 16116604\n",
      "24\n",
      "107 16025583\n",
      "25\n",
      "110 16352077\n",
      "26\n",
      "108 16205602\n",
      "27\n",
      "110 16596125\n",
      "28\n",
      "121 16635570\n",
      "29\n",
      "142 16922619\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "result_all_list=[]\n",
    "date=pd.to_datetime(date_str)\n",
    "for cnt in range(date_step):\n",
    "    \n",
    "    unique_points=pd.concat([data['place1'],data['place2']],ignore_index=True).drop_duplicates()\n",
    "    point_info=pd.DataFrame(columns=['place','res','max_flow','in_flow','out_flow'])\n",
    "    for index, value in unique_points.iteritems():\n",
    "        if value=='DC9':\n",
    "            continue\n",
    "        in_flow=prediction[(prediction['ds']==date)&(prediction['place2']==value)&(prediction['place1']!='DC5') ]['yhat'].sum( )\n",
    "        out_flow=prediction[(prediction['ds']==date)&(prediction['place1']==value)&(prediction['place2']!='DC5')]['yhat'].sum( )\n",
    "        res=out_flow-in_flow\n",
    "        \n",
    "        max_in_sum_1_temp=data[(data['place2']==value)].groupby('date').sum()\n",
    "        max_in_sum_1=max_in_sum_1_temp['num'].max()\n",
    "        max_in_sum_2_temp=prediction[(prediction['place2']==value)][['yhat','ds']].groupby('ds').sum()\n",
    "        max_in_sum_2=max_in_sum_2_temp['yhat'].max()\n",
    "        if np.isnan(max_in_sum_1):\n",
    "            max_in_sum_1=0\n",
    "        if np.isnan(max_in_sum_2):\n",
    "            max_in_sum_2=0\n",
    "        max_in_sum=max(max_in_sum_1,max_in_sum_2)\n",
    "        \n",
    "        max_out_sum_1_temp=data[(data['place1']==value)].groupby('date').sum()\n",
    "        max_out_sum_1=max_out_sum_1_temp['num'].max()\n",
    "        max_out_sum_2_temp=prediction[(prediction['place1']==value)].groupby('ds').sum()\n",
    "        max_out_sum_2=max_out_sum_2_temp['yhat'].max()\n",
    "        if np.isnan(max_out_sum_1):\n",
    "            max_out_sum_1=0\n",
    "        if np.isnan(max_out_sum_2):\n",
    "            max_out_sum_2=0\n",
    "        max_out_sum=max(max_out_sum_1,max_out_sum_2)\n",
    "        \n",
    "        point_info.loc[index]=[value,res,max(max_in_sum,max_out_sum),in_flow,out_flow]\n",
    "    point_info=point_info.reset_index()\n",
    "    point_info.head()\n",
    "    \n",
    "    \n",
    "    unique_routes = data[['place1', 'place2']].drop_duplicates()\n",
    "    edge_info=pd.DataFrame(columns=['max_flow','place1','place2','current_flow','is_new_flow'])\n",
    "    for index, row in unique_routes.iterrows():\n",
    "        place1,place2=row['place1'],row['place2']\n",
    "        if 'DC9' in [place1,place2]:\n",
    "            continue\n",
    "        max_flow_1=data[(data['place1']==place1) & (data['place2']==place2)]['num'].max()\n",
    "        max_flow_2=prediction[(prediction['place1']==place1) & (prediction['place2']==place2)]['yhat'].max()\n",
    "        max_flow=max(max_flow_1,max_flow_2)\n",
    "        current_flow=prediction[(prediction['ds']==date) & (prediction['place1']==place1) & (prediction['place2']==place2)]['yhat'].values[0]\n",
    "        edge_info.loc[index]=[max_flow,place1,place2,current_flow,False]\n",
    "\n",
    "    nodes = set(edge_info['place1']).union(set(edge_info['place2']))\n",
    "    node_combinations = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "    # Find missing edges\n",
    "    existing_edges = set(zip(edge_info['place1'], edge_info['place2']))\n",
    "    missing_edges = [edge for edge in node_combinations if edge not in existing_edges and edge[::-1] not in existing_edges]\n",
    "\n",
    "    # Add missing edges to edge_info\n",
    "    for place1, place2 in missing_edges:\n",
    "        edge_info.append({'max_flow': max_edge_flow, 'place1': place1, 'place2': place2, 'current_flow': 0,'is_new_flow':True}, ignore_index=True)\n",
    "        edge_info.append({'max_flow': max_edge_flow, 'place1': place2, 'place2': place1, 'current_flow': 0,'is_new_flow':True}, ignore_index=True)\n",
    "\n",
    "    edge_info=edge_info.reset_index()\n",
    "    edge_info.head() \n",
    "    \n",
    "    \n",
    "    # 创建有向图\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 添加节点\n",
    "    G.add_node('s')  # 源节点\n",
    "    G.add_node('t')  # 汇节点 \n",
    "\n",
    "    for index, row in point_info.iterrows():\n",
    "        point,max_flow,res,in_flow,out_flow=row['place'],row['max_flow'],row['res'],row['in_flow'],row['out_flow']\n",
    "        G.add_node(point)\n",
    "        G.add_node(point+'-pre')\n",
    "        G.add_node(point+'-next')\n",
    "        \n",
    "        G.add_edge(point+'-pre', point, capacity=max(max_flow-in_flow,0), weight=0,flow=0,origin_capacity=max(0,max_flow-in_flow))\n",
    "        G.add_edge(point, point+'-next', capacity=max(max_flow-out_flow,0), weight=0,flow=0,origin_capacity=max(0,max_flow-in_flow))\n",
    "\n",
    "\n",
    "    # print(G.nodes())\n",
    "    # 添加边\n",
    "    for index, row in edge_info.iterrows():\n",
    "        u,v,max_flow,current_flow,is_new_flow=row['place1'],row['place2'],row['max_flow'],row['current_flow'],row['is_new_flow']\n",
    "        cost=cost_func(u,v,True,current_flow,max_flow,is_new_flow)\n",
    "        G.add_edge(u+'-next', v+'-pre', capacity=max(0,max_flow-current_flow), weight=cost,flow=current_flow,origin_capacity=max_flow)\n",
    "\n",
    "    for index, row in point_info.iterrows():\n",
    "        place,res,max_flow=row['place'],row['res'],row['max_flow']\n",
    "        if res>0:\n",
    "            G.add_edge('s', place+'-pre', capacity=1e8, weight=0,flow=0,origin_capacity=1e8)\n",
    "        else:\n",
    "            G.add_edge(place+'-next', 't', capacity=1e8, weight=0,flow=0,origin_capacity=1e8)\n",
    "\n",
    "\n",
    "    flow_to_DC9=prediction[(prediction['ds']==date) & (prediction['place2']=='DC9')]['yhat'].sum()\n",
    "    flowDict=nx.max_flow_min_cost(G, 's', 't', capacity='capacity', weight='weight')\n",
    "    max_flow=sum(flowDict[node1][node2] for node1 in flowDict for node2 in flowDict[node1])\n",
    "    print(flow_to_DC9,max_flow)\n",
    "    min_cost_list=[]\n",
    "    flow_dict_list=[]\n",
    "\n",
    "    add_num,i=1,0\n",
    "    while i<flow_to_DC9:\n",
    "        # print(f'{i}/{flow_to_DC9}')\n",
    "        i+=add_num\n",
    "        if add_num<step:\n",
    "            add_num+=1\n",
    "        G.nodes['s']['demand']=-add_num\n",
    "        G.nodes['t']['demand']=add_num\n",
    "        flowDict = nx.min_cost_flow(G, demand=\"demand\", capacity='capacity', weight='weight')\n",
    "        # min_cost=nx.cost_of_flow(G,flowDict)\n",
    "        # min_cost_list.append(min_cost)\n",
    "        flow_dict_list.append(flowDict)\n",
    "        # print(min_cost)\n",
    "        for u, v in G.edges():\n",
    "            if flowDict[u][v]!=0:\n",
    "                # print(u,v,flowDict[u][v])\n",
    "                G[u][v]['capacity']-=flowDict[u][v]\n",
    "                G[u][v]['flow']  += flowDict[u][v]\n",
    "                G[u][v]['weight']=cost_func(u,v,False,G[u][v]['flow'],G[u][v]['origin_capacity'],False)\n",
    "                # print(u,v,G[u][v]['weight'])\n",
    "                \n",
    "                \n",
    "    result_all_list.append(flow_dict_list)\n",
    "    date=date+pd.DateOffset(days=1)\n",
    "    print(cnt)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "date=pd.to_datetime(date_str)\n",
    "for index,flow_dict_list in enumerate(result_all_list):\n",
    "    result_dict={}\n",
    "    for d in flow_dict_list:\n",
    "        for k1, v1 in d.items():\n",
    "            if k1 not in result_dict:\n",
    "                result_dict[k1] = {}\n",
    "            for k2, v2 in v1.items():\n",
    "                result_dict[k1][k2] = result_dict[k1].get(k2, 0) + v2\n",
    "    result_dict_new={}          \n",
    "    for k1,v1 in result_dict.items():\n",
    "        for k2,v2 in v1.items():\n",
    "            if v2!=0:\n",
    "                k1=k1.replace('-pre','').replace('-next','')\n",
    "                k2=k2.replace('-pre','').replace('-next','')\n",
    "                if k1==k2:\n",
    "                    continue\n",
    "                if k1 not in result_dict_new:\n",
    "                    result_dict_new[k1] = {}\n",
    "                result_dict_new[k1][k2] = v2\n",
    "    result_dict=result_dict_new\n",
    "    for k1,v1 in result_dict.items():\n",
    "        for k2,v2 in v1.items():\n",
    "            if not(k1=='s' or k2=='t'):\n",
    "                max_flow=edge_info[(edge_info['place1']==k1) & (edge_info['place2']==k2)]['max_flow'].values[0]\n",
    "                origin_flow=edge_info[(edge_info['place1']==k1) & (edge_info['place2']==k2)]['current_flow'].values[0]\n",
    "                is_new_flow=edge_info[(edge_info['place1']==k1) & (edge_info['place2']==k2)]['is_new_flow'].values[0]\n",
    "                result_dict[k1][k2] = [v2,(v2+origin_flow)/max_flow,max_flow,origin_flow,is_new_flow]\n",
    "            else:\n",
    "                result_dict[k1][k2] = [v2,0,0,0,False]\n",
    "    df_list.append(pd.DataFrame([(k1, k2, v2[0],v2[1],v2[2],v2[3],date,v2[4]) for k1,v1 in result_dict.items() for k2,v2 in v1.items()], columns=['place1', 'place2', 'flow','load_rate','max_flow','origin_flow','date','is_new_create']))\n",
    "    date=date+pd.DateOffset(days=1)\n",
    "    \n",
    "df = pd.concat(df_list)\n",
    "df.to_csv('problem3_all.csv', index=True)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mothercup2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
